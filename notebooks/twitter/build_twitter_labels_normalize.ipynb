{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "from utils.datasets import ensure_dataset\n",
    "HOUR = 3600\n",
    "DAY = HOUR * 24\n",
    "CURRENCIES = [\n",
    "    'USD-BTC',\n",
    "    'USD-ETH',\n",
    "    # 'USD-XRP',\n",
    "    # 'USD-LINK',\n",
    "]\n",
    "\n",
    "TIMEFRAMES = {\n",
    "    '-12h': -HOUR * 8,\n",
    "    '12h': HOUR * 12,\n",
    "    '1d': DAY,\n",
    "    '2d': DAY * 2,\n",
    "    '7d': DAY * 7,\n",
    "    '14d': DAY * 14,\n",
    "}\n",
    "\n",
    "FEATURES = [\n",
    "    f'feat-{CURRENCY}-change-{label}'\n",
    "    for label, delta in TIMEFRAMES.items()\n",
    "    for CURRENCY in CURRENCIES\n",
    "]\n",
    "\n",
    "OUTPUT_PATH = '../../data/bitcoin_twitter_labeled_normalized/'\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "ensure_dataset(OUTPUT_PATH, delete=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "scalers = {feat: StandardScaler() for feat in FEATURES}\n",
    "files = pathlib.Path(\"../../data/bitcoin_twitter_labeled/\").glob(\"part_*.parquet\")\n",
    "for chunk, file in enumerate(files):\n",
    "    data = pd.read_parquet(file)\n",
    "    for feature in FEATURES:\n",
    "        values = np.array(data[feature][data[feature].notna()])\n",
    "        if len(values) == 0: continue\n",
    "        scalers[feature].partial_fit(values.reshape(-1, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat-USD-BTC-change--12h: mean=[-0.00063452], var=[0.00064957]\n",
      "feat-USD-ETH-change--12h: mean=[-0.00064972], var=[0.00143441]\n",
      "feat-USD-BTC-change-12h: mean=[0.00100798], var=[0.00083298]\n",
      "feat-USD-ETH-change-12h: mean=[0.00186295], var=[0.00167703]\n",
      "feat-USD-BTC-change-1d: mean=[0.00265909], var=[0.0017914]\n",
      "feat-USD-ETH-change-1d: mean=[0.00495193], var=[0.00385489]\n",
      "feat-USD-BTC-change-2d: mean=[0.00526322], var=[0.00364077]\n",
      "feat-USD-ETH-change-2d: mean=[0.01021734], var=[0.00828368]\n",
      "feat-USD-BTC-change-7d: mean=[0.02043608], var=[0.01416145]\n",
      "feat-USD-ETH-change-7d: mean=[0.03836635], var=[0.03703305]\n",
      "feat-USD-BTC-change-14d: mean=[0.04383856], var=[0.03605598]\n",
      "feat-USD-ETH-change-14d: mean=[0.08239824], var=[0.08814765]\n"
     ]
    }
   ],
   "source": [
    "for feature in FEATURES:\n",
    "    print(f'{feature}: mean={scalers[feature].mean_}, var={scalers[feature].var_}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 0\n",
      "Processing chunk 1\n",
      "Processing chunk 2\n",
      "Processing chunk 3\n",
      "Processing chunk 4\n",
      "Processing chunk 5\n",
      "Processing chunk 6\n",
      "Processing chunk 7\n",
      "Processing chunk 8\n",
      "Processing chunk 9\n",
      "Processing chunk 10\n",
      "Processing chunk 11\n",
      "Processing chunk 12\n"
     ]
    }
   ],
   "source": [
    "files = pathlib.Path(\"../../data/bitcoin_twitter_labeled/\").glob(\"part_*.parquet\")\n",
    "for chunk, file in enumerate(files):\n",
    "    data = pd.read_parquet(file)\n",
    "    print(f'Processing chunk {chunk}')\n",
    "    for feature in FEATURES:\n",
    "        data = data[data[feature].notna()]\n",
    "        if len(data) == 0: break\n",
    "        values = np.array(data[feature]).reshape(-1, 1)\n",
    "        data[feature] = scalers[feature].transform(values).reshape(-1)\n",
    "    if len(data) == 0:\n",
    "        continue\n",
    "    data.to_parquet(os.path.join(OUTPUT_PATH, f\"part_{chunk}.parquet\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}