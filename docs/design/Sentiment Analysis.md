# Sentiment Analysis Design Doc
* Input text batch (features / embeddings)
* Label: short 0.5d, mid 2d, long 7d, long long 14d price delta


## Resources / Citation
* https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#2-input-formatting
* https://github.com/LydiaXiaohongLi/Albert_Finetune_with_Pretrain_on_Custom_Corpus
* https://towardsdatascience.com/fine-tune-albert-with-pre-training-on-custom-corpus-f56ea3cfdc82
* https://github.com/google-research/albert/issues/127#issuecomment-581869983
* https://towardsdatascience.com/from-pre-trained-word-embeddings-to-pre-trained-language-models-focus-on-bert-343815627598
* https://towardsdatascience.com/fine-tune-albert-with-pre-training-on-custom-corpus-f56ea3cfdc82
* https://github.com/VinAIResearch/BERTweet
* https://github.com/huggingface/transformers/issues/1413
* https://colab.research.google.com/drive/1fXFH7g4nfbxBo42icI4ZMy-0TAGAxc2i
  
* https://github.com/cybo1112/cantoformer/blob/2c519ef9a703c382b8f0d39c40f34bbf59a47ca9/.ipynb_checkpoints/pretrain_tpu-checkpoint.ipynb
* https://github.com/huggingface/transformers/blob/30b2dbbba6918ac6540b6a1758b7ee19f0ac969c/examples/run_efficient_pretraining.py

## Citation / Papers
* https://www.frontiersin.org/articles/10.3389/fphy.2019.00098/full

## Other approaches
* Gradient Boosting: https://www.kaggle.com/kamalnaithani/lightgbm-stock-prediction-1-1